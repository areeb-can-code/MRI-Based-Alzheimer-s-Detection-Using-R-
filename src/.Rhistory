###install.packages('yardstick')
library(yardstick)
caret::confusionMatrix(df_pred$pred, df_pred$mpg_discrete, positve="H") )
caret::confusionMatrix(df_pred$pred, df_pred$mpg_discrete, positve="H")
caret::confusionMatrix(df_pred$pred, df_pred$mpg_discrete, positve="H")
# Making a confusino Matricx
df_pred <-  data.frame(pred, mpg_discrete <- test$mpg_discrete)
###install.packages('yardstick')
library(yardstick)
caret::confusionMatrix(df_pred$pred, df_pred$mpg_discrete, positve="H")
## Assignment 3 Hell but I'm Proud ####
giniInit <-1- (12/25)^2 - (13/25)^2
giniInit
giniWarm  <- 1-(4/8)^2-(4/8)^2
giniWarm  <- 1-(4/8)^2-(4/8)^2
giniCold <- 1-(5/8)^2-(3/8)^2
giniHot <- 1-(3/9)^2-(6/9)^2
giniWarm
giniCol
giniCold
giniHot
giniWeather <- 8/25*giniWarm + 8/25 * giniCold + 9/25 *giniHot
giniWeather
giniInit - giniWeather
giniSunny <- 1- (9/16)^2 - (7/16)^2
giniSunny
giniRainy <- 1- (3/9)^2 - (6/9)^2
giniRainy
giniWeather <-  16/25*giniSunny + 9/25 * giniRainy
giniInit - giniWeather
entropyInit <- - (1/6) log2() * (1/6)-(5/6) log2() * (1/6)
entropyInit <-  (1/6) log2() * (1/6)-(5/6) log2() * (1/6)
entropyInit <-  (1/6) *log2() * (1/6)-(5/6)* log2() * (1/6)
entropyInit <- - (1/6) *log2(1/6) -(5/6)* log2(1/6)
entropyInit
entropyInit <- -log2(1/6) * 1/6-log(5/6) * (1/6)
entropyInit
entropyInit <- -(log2(1/6) * 1/6-log(5/6) * (1/6))
entropyInit
entropyInit <- -(log2(1/6)) * 1/6-(log(5/6)) * (1/6)
entropyInit
entropyInit <- -(1/6) log2(1/6) - (5/6) * log2(1/6)
entropyInit <- -(1/6)* log2(1/6) - (5/6) * log2(1/6)
entropyInit
entropyInit <- -(1/6)-log2(1/6) - (5/6) - log2(1/6)
entropyInit
entropyInit <- -(1/6)* log2(1/6)^2 - (5/6) * log2(1/6)^2
entropyInit
entropyInit <- -(1/6)+ log2(1/6) - (5/6) + log2(1/6)
entropyInit
entropyInit <- -(1/6)+ log2(1/6) - (5/6) + log2(5/6)
entropyInit
entropyInit <- -(1/6)* log2(1/6) - (5/6) *log2(5/6)
entropyInit
entropyInit <- -(12/25)* log2(12/25) - (13/25) *log2(13/25)
entropyInit
entropySunny <- -(9/16)* log2(9/16) - (7/16) *log2(7/16)
entropySunny
entropyRainy <- -(3/9)* log2(3/9) - (6/9) *log2(6/9)
entropyRainy
entropyWeather <- entropyInit - entropySunny (16/25)
entropyWeather <- entropyInit - entropySunny (16/25)- entropyRainy (9/25)
entropySunny <- -(9/16)* log2(9/16) - (7/16) *log2(7/16)
entropySunny
entropyRainy <- -(3/9)* log2(3/9) - (6/9) *log2(6/9)
entropyRainy
entropyWeather <- entropyInit - entropySunny (16/25)- entropyRainy (9/25)
entropyWeather <- entropyInit - entropySunny*(16/25)- entropyRainy* (9/25)
entropyWeather
## Assignment 3 Hell but I'm Proud ####
giniInit <-1- (12/25)^2 - (13/25)^2
giniInit
giniWarm  <- 1-(4/8)^2-(4/8)^2
giniCold <- 1-(5/8)^2-(3/8)^2
giniHot <- 1-(3/9)^2-(6/9)^2
giniWarm
giniCold
giniHot
giniWeather <- 8/25*giniWarm + 8/25 * giniCold + 9/25 *giniHot
giniWeather
giniInit - giniWeather
giniSunny <- 1- (9/16)^2 - (7/16)^2
giniRainy <- 1- (3/9)^2 - (6/9)^2
giniRainy
giniWeather <-  16/25*giniSunny + 9/25 * giniRainy
giniInit - giniWeather
entropyInit <- -(12/25)* log2(12/25) - (13/25) *log2(13/25)
entropyInit
entropySunny <- -(9/16)* log2(9/16) - (7/16) *log2(7/16)
entropySunny
entropyRainy <- -(3/9)* log2(3/9) - (6/9) *log2(6/9)
entropyRainy
entropyWeather <- entropyInit - entropySunny*(16/25)- entropyRainy* (9/25)
entropyWeather
install.packages(c("backports", "class", "dbplyr", "dplyr", "ellipsis", "ggplot2", "git2r", "glue", "haven", "later", "modelr", "nlme", "nnet", "pillar", "pkgbuild", "pkgload", "ps", "rematch2", "rex", "rlang", "rmarkdown", "rversions", "scales", "SQUAREM", "tibble", "tidyr", "tidyselect", "tinytex", "usethis", "vctrs", "withr", "xfun", "xml2"))
#MRI and Alzheimers:
# MMSE -> Mini Mental State Evaluation
# CDR -> Clinical Dementia Rating
# eTIV -> Estimated Total Intracranial Volume
# nWBV -> Normalize Whole Brain Volume
# ASF -> Atlas Scaling Factor
summary(mri2)
#install.packages("ggplot2")
library(caret)
library(tidyverse)
library(rattle)
library(e1071)
library(readr)
library(rpart.plot)
library(ggplot2)
library(caTools)
int.volume <- mri2$eTIV * mri2$nWBV
p <- ggplot(data = mri2, aes(x = Age, y = nWBV,
color = Group, size = CDR))
p + geom_jitter() + labs(x= "Age" ,
y= "Normalize Brain Volume",
size="Clinical Dementia Rating",
title= "Age vs Brain Volume")
p <- ggplot(data = mri2, aes(x = MMSE, y = CDR,
color = Group))
p + geom_jitter(size = 3)
plot(mri2)
group.model <- lm(nWBV ~ Group, data = mri2)
summary #0.09525 (p = 1.09e-06)
visit.model <- lm(nWBV ~ Visit, data = mri2)
summary(visit.model) #0.01435 (p = 0.0144)
plot(visit.model)
mr.delay.model <- lm(nWBV ~ MR.Delay, data = mri2)
summary(mr.delay.model)  #0.008483 (p  = 0.0415)
plot(mr.delay.model)
M.F.model <- lm(nWBV ~ M.F, data = mri2)
summary(M.F.model)  #0.05978 (p = 1.05e-06)
age.model <- lm(nWBV ~ Age, data = mri2)
summary(age.model)  #0.2667 (p = 2e-16)
edu.model <- lm(nWBV ~ EDUC, data = mri2)
summary(edu.model) #0.8143 (p = 0.814)
ses.model <- lm(nWBV ~ SES, data = mri2)
summary(ses.model) #0.09054 (p = 0.0905)
cdr.model <- lm(nWBV ~ CDR, data = mri2)
summary(cdr.model) #0.1165 (p = 7.47e-12)
etiv.model <- lm(nWBV ~ eTIV, data = mri2)
summary(etiv.model) #0.04157 (p = 4.31-05)
asf.model <- lm(nWBV ~ ASF, data = mri2)
summary(asf.model) #0.043 (p = 3.22e-05)
fs.model1 <- lm(nWBV ~ Age + CDR + M.F, data = mri2)
summary(fs.model1)
#------------------------- Backward Elimination
be.model1 <- lm(nWBV ~ Group + Visit + MR.Delay + M.F + Age + EDUC + SES + MMSE +
CDR + eTIV + ASF, data = mri2)
summary(be.model1)
be.model2 <- lm(nWBV ~ Group + MR.Delay + M.F + Age + EDUC + SES + MMSE +
CDR + eTIV + ASF, data = mri2)
summary(be.model2)
be.model3 <- lm(nWBV ~ Group + MR.Delay + M.F + Age + SES + MMSE +
CDR + eTIV + ASF, data = mri2)
summary(be.model3)
be.model4 <- lm(nWBV ~ Group + M.F + Age + SES + MMSE +
CDR + eTIV + ASF, data = mri2)
summary(be.model4)
be.model5 <- lm(nWBV ~ MR.Delay + M.F + Age + SES + MMSE +
CDR + eTIV + ASF, data = mri2)
summary(be.model5)
be.model6 <- lm(nWBV ~  M.F + Age + SES + MMSE +
CDR + eTIV + ASF, data = mri2)
summary(be.model6)
be.model7 <- lm(nWBV ~  M.F + Age + SES + MMSE +
CDR + eTIV, data = mri2)
summary(be.model7)
int.mmse.cdr <- mri2$MMSE * mri2$CDR
be.model8 <- lm(nWBV ~  M.F + Age + SES + MMSE + CDR
, data = mri2)
summary(be.model8)
#----------------- Visualizations
#Scatterplot -> Age and Normalized Whole Brain Volume (Group and Clinical Dementia Rating)
u <- ggplot(data = mri2, aes(x = Age, y = nWBV,
color = Group, size = CDR))
u+ geom_point()
u + geom_point() + geom_smooth(fill = NA)
#Boxplot:
b <- ggplot(data =filteredD, aes(x = Age, y = nWBV,
color = Group))
b + geom_boxplot()
b + geom_boxplot(size = 1.2) +
labs(title="Age vs Brain Volume",
x = "Age",
y="Normalized Brain Volume") +geom_bar()
brainVol <-  filteredD%>%
ggplot(aes(x=nWBV, fill= Group)) +
geom_histogram(bins=15) + labs(x="Normalized Brain Volume",
title= "Histogram of Brain Vol")
brainVol
geom_boxplot(size = 1.2) +
geom_point()
b + geom_boxplot(size = 1.2) + geom_jitter()
b + geom_jitter() + geom_boxplot(size = 1.2, alpha = 0.5)
# Scatter/Line Plot -> ASF and Normalized Whole Brain Volume (Including M/F, Clinical Dementia Rating)
ggplot(data = mri2,
aes(x = ASF, y = nWBV, color = M.F, size = CDR)) +
geom_point() +
labs(title = "ASF vs nWBV",
x= "Atlas Scaling Factor",
y= "Normalize Brain Volume",
size= "Clinical Demented Rating")
#### JUSTUS CONTRIBU ####
#cross sectional file
mri1 <- read.csv("oasis_cross-sectional.csv")
mri2 = read.csv("oasis_longitudinal.csv")
library(ggplot2)
library(tidyverse)
mri3 = mri2 %>% select(MMSE, CDR, EDUC, SES, nWBV)
summary(mri2)
ggplot(mri2, aes(x = ASF, y = as.factor(CDR))) + geom_boxplot()
ggplot(mri2, aes(x = SES, y = as.factor(CDR),color=Group)) + geom_jitter()
ggplot(mri2,
aes(x = nWBV, y = ASF,
color = as.factor(CDR))) +
geom_point() + geom_smooth()
ggplot(mri2, aes(x = nWBV, y = ASF, color = as.factor(MMSE))) + geom_point()
lm1 = lm(formula = CDR ~ ASF + eTIV + nWBV, data = mri2)
summary(lm1)
lm2 = lm(formula = MMSE ~ ASF + eTIV + nWBV, data = mri2)
summary(lm2)
lm3 = lm(formula = CDR ~ EDUC + SES, data = mri2)
summary(lm3)
lm4 = lm(formula = MMSE ~ EDUC + SES, data = mri2)
summary(lm4)
cormri = cor(mri3)
ggcorrplot::ggcorrplot(cormri, type = 'lower')
lm6 = lm(formula = CDR ~ nWBV + EDUC + M.F + Age,
data = filteredD)
summary(lm6)
samp <- sample.split(Y=filteredD$Group, SplitRatio = 0.70)
filteredD <- mri2%>%
filter(Group %in% c("Demented", "Nondemented"))
dem_train <-filteredD[samp==TRUE,] ## train set
dem_test <- filteredD[samp== FALSE, ]
decisionmri <- rpart(Group ~ EDUC+ nWBV+Age , data = dem_train)
names(mri2)
p <- ggplot(data = filteredD, aes(x = Age, y = nWBV,
color = Group, size = CDR))
p + geom_jitter() + labs(x= "Age" ,
y= "Normalize Brain Volume",
size="Clinical Dementia Rating",
title= "Age vs Brain Volume")
p + geom_jitter() + labs(x= "Age" ,
y= "Normalize Brain Volume",
size="Clinical Dementia Rating",
title= "Age vs Brain Volume")
age <- filteredD%>%
ggplot(aes(x=EDUC, y= nWBV, size= Group, size= CDR)) +
geom_jitter()
age <- filteredD%>%
ggplot(aes(x=EDUC, y= nWBV, size= Group)) +
geom_jitter()
age
age <- filteredD%>%
ggplot(aes(x=EDUC, y= nWBV, size= CDR, color= Group)) +
geom_jitter()
age
age <- filteredD%>%
ggplot(aes(x=EDUC, y= nWBV, size= CDR, color= Group)) +
geom_jitter() + labs(x="Education",
y= "Normalized Brain Volume",
title="Education vs Brain Volume")
age
#### MATT'S YA BITCH ####
ocs <- (data = oasis_cross.sectional)
# confusion matrix setup
library(caret)
#### MATT'S YA BITCH ####
ocs <- read.csv( 'oasis_cross.sectional.csv')
## Dong R Code for Week 10
library(tidyverse)
library(caret)
library(caTools)
data(iris)
force(iris)
iris
iris %>%
ggplot(aes(x=Petal.Length, y=Petal.Width, color=Species)) +
geom_point() + geom_line()
iris %>%
ggplot(aes(x=Petal.Length, y=Petal.Width, color=Species)) +
geom_point() + geom_smooth()
## using Kmeans with centroids (how many clusters)
irisNoLabs <- iris %>%
select(-Species)
# the centers thing tells you what your K value is
kmeans(irisNoLabs, centers = 3)
kmeans
?kmeans
# the centers thing tells you what your K value is
kmeans(irisNoLabs, centers = 3)
clusters$cluster
# the centers thing tells you what your K value is
clusters <- kmeans(irisNoLabs, centers = 3)
clusters$cluster
plot(clusters)
plot(clusters$cluster, clusters$withinss)
table(clusters$cluster, iris$Species)
print("cluster
A vector of integers (from 1:k) indicating the cluster to which each point is allocated.
centers
A matrix of cluster centres.
totss
The total sum of squares.
withinss
Vector of within-cluster sum of squares, one component per cluster.
tot.withinss
Total within-cluster sum of squares, i.e. sum(withinss).
betweenss
The between-cluster sum of squares, i.e. totss-tot.withinss.
size
The number of points in each cluster.
iter
The number of (outer) iterations.
ifault
integer: indicator of a possible algorithm problem – for experts.")
clusters$centers
clusters$withinss
clusters$tot.withinss
set.seed(1)
data(iris)
iris
iris %>%
ggplot(aes(x=Petal.Length, y=Petal.Width, color=Species)) +
geom_point() + geom_smooth()
## using Kmeans with centroids (how many clusters)
irisNoLabs <- iris %>%
select(-Species)
# the centers thing tells you what your K value is
clusters <- kmeans(irisNoLabs, centers = 3)
kmeans
?kmeans
clusters$cluster
table(clusters$cluster, iris$Species)
print("cluster
A vector of integers (from 1:k) indicating
the cluster to which each point is allocated.
centers
A matrix of cluster centres.
totss
The total sum of squares.
withinss
Vector of within-cluster sum of squares, one component per cluster.
tot.withinss
Total within-cluster sum of squares, i.e. sum(withinss).
betweenss
The between-cluster sum of squares, i.e. totss-tot.withinss.
size
The number of points in each cluster.
iter
The number of (outer) iterations.
ifault
integer: indicator of a possible algorithm problem – for experts.")
clusters$centers
clusters$withinss
clusters$tot.withinss
tot_within_ss <- numeric(length = 20) #k val)
tot_within_ss
## checking optimal amt of k w/ line plot ####
optimus <- data.frame(k=seq(1,20), tot_within_ss)
## making the plot ####
optimus %>%
ggplot(aes(x=k, y=tot_within_ss) color=color)) +
geom_point() + geom_smooth()
## making the plot ####
optimus %>%
ggplot(aes(x=k, y=tot_within_ss) color=color)) +
geom_point() + geom_smooth()
## Dong R Code for Week 10
library(tidyverse)
library(caret)
library(caTools)
set.seed(1)
data(iris)
iris
iris %>%
ggplot(aes(x=Petal.Length, y=Petal.Width, color=Species)) +
geom_point() + geom_smooth()
## using Kmeans with centroids (how many clusters)
irisNoLabs <- iris %>%
select(-Species)
# the centers thing tells you what your K value is
clusters <- kmeans(irisNoLabs, centers = 3)
kmeans
?kmeans
clusters$cluster
table(clusters$cluster, iris$Species)
print("cluster
A vector of integers (from 1:k) indicating
the cluster to which each point is allocated.
centers
A matrix of cluster centres.
totss
The total sum of squares.
withinss
Vector of within-cluster sum of squares, one component per cluster.
tot.withinss
Total within-cluster sum of squares, i.e. sum(withinss).
betweenss
The between-cluster sum of squares, i.e. totss-tot.withinss.
size
The number of points in each cluster.
iter
The number of (outer) iterations.
ifault
integer: indicator of a possible algorithm problem – for experts.")
clusters$centers
clusters$withinss
clusters$tot.withinss
tot_within_ss <- numeric(length = 20) #k val)
for (k in seq(1,20)) {
clusters <- kmeans(irisNoLabs, centers=k)
tot_within_ss[k] <- clusters$tot.withinss
}
tot_within_ss
## checking optimal amt of k w/ line plot ####
optimus <- data.frame(k=seq(1,20), tot_within_ss)
## making the plot ####
optimus %>%
ggplot(aes(x=k, y=tot_within_ss) color=color)) +
geom_point() + geom_smooth()
u
## making the plot ####
optimus %>%
ggplot(aes(x=k, y=tot_within_ss, color=color)) +
geom_point() + geom_smooth()
names(color)
## making the plot ####
optimus %>%
ggplot(aes(x=k, y=tot_within_ss, color=iris$Species)) +
geom_point() + geom_smooth()
## making the plot ####
optimus %>%
ggplot(aes(x=k, y=tot_within_ss)) +
geom_point() + geom_smooth()
## now let's see how different k clusters affect the sizes on the plot####
data(iris)
force(iris)
irisSmol <- iris
## now let's see how different k clusters affect the sizes on the plot####
clusters <- kmeans(irisNoLabs, centers = 3)
iris$clusters3 <- clusters$cluster
clusters <- kmeans(irisNoLabs, centers=4)
iris$clusters4 <- clusters$cluster
iris%>%
ggplot(aes(x=Petal.Length, y=Petal.Width, color=iris$clusters3)) +
geom_point() + geom_smooth()
iris%>%
lol
iris%>%
iris%>%
ggplot(aes(x=Petal.Length, y=Petal.Width, color=factor(iris$clusters3))) +
geom_point() + geom_smooth()
irisSmol%>%
ggplot(aes(x=Petal.Length, y=Petal.Width, color=factor(iris$clusters3))) +
geom_point() + geom_smooth()
irisSmol%>%
ggplot(aes(x=Petal.Length, y=Petal.Width, color=factor(iris$clusters4))) +
geom_point() + geom_smooth()
iris%>%
ggplot(aes(x=Petal.Length, y=Petal.Width, color=factor(iris$clusters4))) +
geom_point() + geom_smooth()
iris%>%
ggplot(aes(x=Petal.Length, y=Petal.Width, color=factor(clusters4))) +
geom_point() + geom_smooth()
## getting rid of other attributes into Smol####
irisSmol <- iris%>%
select(Petal.Length, Petal.Width)
irisSmol%>%
ggplot(aes(x=Petal.Length, y=Petal.Width, color=factor(clusters4))) +
geom_point() + geom_smooth()
iris%>%
ggplot(aes(x=Petal.Length, y=Petal.Width, color=factor(clusters4))) +
geom_point() + geom_smooth()
#paritinoned 4 of dem part 2 ####
clusters <- kmeans(irisSmol, centers=4)
iris$clusters4 <- clusters$cluster
# k = 3 in this one part 2 #####
clusters <- kmeans(irisSmol, centers = 3)
iris$clusters3 <- clusters$cluster
iris%>%
ggplot(aes(x=Petal.Length, y=Petal.Width, color=factor(clusters4))) +
geom_point() + geom_smooth()
iris%>%
ggplot(aes(x=Petal.Length, y=Petal.Width, color=factor(clusters3))) +
geom_point() + geom_smooth()
centXYellow <- mean(c(4,5,5,5,5,6))
centXYellow
centYYellow <- mean(c(1,2,3,4,4,5))
centYYellow
## Blue cluster Iteration 2 ####
centXBlue <- mean(2,2,3,3,3,3,4,4)
centXBlue
centXBlue
## Blue cluster Iteration 2 ####
centXBlue <- mean(c(2,2,3,3,3,3,4,4))
centXBlue
centYBlue <- mean(c(1,1,2,2,2,3,3,5))
centYBlue
sqrt(.5)
sqrt(2)
sqrt(3)
1/(sqrt(2))^2
1.414214^2
sqrt(3)
sqrt(3)^2
library(tidyr)
library(tidyverse)
library(readr)
library(dplyr)
